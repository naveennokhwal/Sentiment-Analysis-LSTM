{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, vectors, labels):\n",
    "        self.vectors = torch.FloatTensor(vectors)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.vectors[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMSentiment(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.5):\n",
    "        super(LSTMSentiment, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, (h_n, _) = self.lstm(x)\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        out = self.fc(h_n[-1])  # Use the last layer's hidden state\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 5\n",
    "            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                               Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Function\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for vectors, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "            vectors, labels = vectors.to(\"cpu\"), labels.to(\"cpu\").float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(vectors.unsqueeze(1))  # Adding sequence dimension\n",
    "            loss = criterion(output.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for vectors, labels in val_loader:\n",
    "                vectors, labels = vectors.to(\"cpu\"), labels.to(\"cpu\")\n",
    "                output = model(vectors.unsqueeze(1))  # Adding sequence dimension\n",
    "                loss = criterion(output.squeeze(), labels)\n",
    "                val_loss += loss.item()\n",
    "                predicted = (output.squeeze() > 0.5).float()\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "        print(f\"Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "        print(f\"Val Accuracy: {correct/total:.4f}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.read_csv(r'C:\\Learning\\Machine-Learning\\Deep_Learning_WorkSpace\\projects\\sentiment-analysis-project\\data\\processed\\vector10000.csv')\n",
    "labels = pd.read_csv(r'C:\\Learning\\Machine-Learning\\Deep_Learning_WorkSpace\\projects\\sentiment-analysis-project\\data\\raw\\label10000.csv')\n",
    "labels = labels['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 300), (10000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(labels.min(), labels.max())\n",
    "print(labels.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1455    0\n",
       "4793    0\n",
       "5335    1\n",
       "74      0\n",
       "7227    1\n",
       "3650    0\n",
       "142     0\n",
       "128     0\n",
       "9980    1\n",
       "141     0\n",
       "7609    1\n",
       "4571    0\n",
       "4140    0\n",
       "5279    1\n",
       "1523    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(vectors, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 300), (2000, 300), (8000,), (2000,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = SentimentDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "input_dim = 300  # Word2Vec dimension\n",
    "hidden_dim = 128\n",
    "output_dim = 1  # Binary classification\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSentiment(\n",
       "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMSentiment(input_dim, hidden_dim, output_dim, n_layers)\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 250/250 [00:02<00:00, 105.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 0.6122\n",
      "Val Loss: 0.5697\n",
      "Val Accuracy: 0.7080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 250/250 [00:02<00:00, 107.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3\n",
      "Train Loss: 0.5521\n",
      "Val Loss: 0.5618\n",
      "Val Accuracy: 0.7190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 250/250 [00:02<00:00, 108.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "Train Loss: 0.5405\n",
      "Val Loss: 0.5686\n",
      "Val Accuracy: 0.6990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    " # Save the model\n",
    "torch.save(model.state_dict(), \"C:\\Learning\\Machine-Learning\\Deep_Learning_WorkSpace\\projects\\sentiment-analysis-project\\\\backend\\models\\lstm_sentiment_model.pth\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(model, vector):\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable gradient calculations (not needed for inference)\n",
    "    with torch.no_grad():\n",
    "        # Add batch dimension to the input vector (shape: [1, 1, sequence_length, input_size])\n",
    "        vector = vector.unsqueeze(0)\n",
    "        \n",
    "        # Pass the vector through the model\n",
    "        output = model(vector)\n",
    "        \n",
    "        # Apply softmax to get the probabilities and then take the argmax to get the predicted class\n",
    "        if output > 0.5 :\n",
    "            return 1\n",
    "        elif output <0.5 :\n",
    "            return 0\n",
    "        else:\n",
    "            return \"unexpected output\"        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
